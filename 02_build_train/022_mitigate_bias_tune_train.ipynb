{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a new model\n",
    "\n",
    "In this second model, you will fix the gender imbalance in the dataset using SMOTE and train another model using XGBoost with hyperparameter tuning and Debugger. This model will also be saved to our registry and eventually approved for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import clarify\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region, boto3 and SageMaker SDK variables¶\n",
    "\n",
    "#You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored variables\n",
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(local_processed_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "\n",
    "One approach to addressing imbalanced datasets is to oversample the minority class. New examples can be synthesized from the existing examples. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique, or SMOTE for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=random_state)\n",
    "\n",
    "df_resampled, _ = sm.fit_resample(df, df['SEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the gender balance\n",
    "df_resampled['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df_resampled, test_size=0.2, random_state=random_state)\n",
    "X_train, X_val = train_test_split(df_resampled, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f'{local_data_dir}/train_res.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/train_res.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_res_data_uri = response\n",
    "%store train_res_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data with header - needed for model monitor baseline job\n",
    "X_train.to_csv(f'{local_data_dir}/train_res_header.csv', header=True, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/train_res_header.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_res_data_header_uri = response\n",
    "%store train_res_data_header_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.to_csv(f'{local_data_dir}/validation_res.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/validation_res.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "validation_res_data_uri = response\n",
    "%store validation_res_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f'{local_data_dir}/test_res.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/test_res.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "test_res_data_uri = response\n",
    "%store test_res_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating XGBoost model with Hyperparameter Tunining and Debugger\n",
    "\n",
    "For SageMaker XGBoost training jobs, use the Debugger `CreateXgboostReport` rule to receive a comprehensive training report of the training progress and results. Following this guide, specify the CreateXgboostReport rule while constructing an XGBoost estimator. The `CreateXgboostReport` rule collects the following output tensors from your training job:\n",
    "\n",
    "* hyperparameters – Saves at the first step.\n",
    "* metrics – Saves loss and accuracy every 5 steps.\n",
    "* feature_importance – Saves every 5 steps.\n",
    "* predictions – Saves every 5 steps.\n",
    "* labels – Saves every 5 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "estimator_output_path = f's3://{default_bucket}/{prefix}/training_jobs'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=hyperparameters,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=estimator_output_path,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will tune four hyperparameters in this examples:\n",
    "\n",
    "* eta: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative.\n",
    "* alpha: L1 regularization term on weights. Increasing this value makes models more conservative.\n",
    "* min_child_weight: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this simply corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is.\n",
    "* max_depth: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'max_depth': IntegerParameter(1, 10),\n",
    "                         'eta': ContinuousParameter(0, 1),\n",
    "                         'gamma': ContinuousParameter(0, 5),\n",
    "                        'alpha': ContinuousParameter(0, 2)\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. Since we are using built-in XGBoost algorithm here, it emits two predefined metrics: validation:auc and train:auc, and we elected to monitor validation:auc as you can see below. In this case, we only need to specify the metric name and do not need to provide regex. If you bring your own algorithm, your algorithm emits metrics by itself. In that case, you'll need to add a MetricDefinition object here to define the format of those metrics through regex, so that SageMaker knows how to extract those metrics from your CloudWatch logs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:f1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a HyperparameterTuner object, to which we pass:\n",
    "\n",
    "* The XGBoost estimator we created above\n",
    "* Our hyperparameter ranges\n",
    "* Objective metric name and definition\n",
    "* Tuning resource configurations such as Number of training jobs to run in total and how many training jobs can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(xgb_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=4,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "# You can increase the number of jobs, etc. I set them to 10, 4 for the demo purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Hyperparameter Tuning job\n",
    "\n",
    "Now we can launch a hyperparameter tuning job by calling fit() function. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "train_input = TrainingInput(train_data_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_data_uri, content_type=\"text/csv\")\n",
    "\n",
    "# execute the XGBoost training job\n",
    "tuner.fit({'train': train_input,\n",
    "                   'validation': validation_input\n",
    "                  }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_smote_job_name = tuner.best_training_job()\n",
    "%store training_smote_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model from estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=training_smote_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store hyperparameters for best training job\n",
    "best_job_hp = training_job_info['HyperParameters']\n",
    "%store best_job_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_name = f'{prefix}-xgboost-smote'\n",
    "\n",
    "\n",
    "model_matches = sagemaker_boto_client.list_models(NameContains=model_2_name)['Models']\n",
    "\n",
    "if not model_matches:\n",
    "    \n",
    "    model_2 = sagemaker_session.create_model_from_job(\n",
    "        name=model_2_name,\n",
    "        training_job_name=training_job_info['TrainingJobName'],\n",
    "        role=sagemaker_role,\n",
    "        image_uri=training_job_info['AlgorithmSpecification']['TrainingImage'])\n",
    "    %store model_2_name\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print(f\"Model {model_2_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store model_2_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_s3_uri = training_job_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=training_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    training_data_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {training_data_artifact.artifact_arn}')\n",
    "else:\n",
    "    training_data_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainingData',\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type='Dataset',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_s3_uri = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=trained_model_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    model_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {model_artifact.artifact_arn}')\n",
    "else:\n",
    "    model_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainedModel',\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type='Model',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {model_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set artifact associations¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(TrialComponentName=tuner.best_training_job()+'-aws-training-job')\n",
    "trial_component_arn = trial_component['TrialComponentArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input artifacts\n",
    "input_artifacts = [training_data_artifact]\n",
    "\n",
    "for a in input_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='ContributedTo',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Associate {trial_component_arn} and {a.artifact_arn}: SUCCEESFUL\\n\")\n",
    "    except:\n",
    "        print(f\"Association already exists between {trial_component_arn} and {a.artifact_arn}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output artifacts\n",
    "\n",
    "output_artifacts = [model_artifact]\n",
    "\n",
    "for artifact_arn in output_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='Produced',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Associate {trial_component_arn} and {a.artifact_arn}: SUCCEESFUL\\n\")\n",
    "    except:\n",
    "        print(f\"Association already exists between {trial_component_arn} and {a.artifact_arn}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Package for the Second Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {'classification_metrics': {}}\n",
    "for metric in training_job_info['FinalMetricDataList']:\n",
    "    stat = {metric['MetricName']: {'value': metric['Value']}}\n",
    "    model_metrics_report['classification_metrics'].update(stat)\n",
    "    \n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "    \n",
    "metrics_s3_key = f\"{prefix}/training_jobs/{training_job_info['TrainingJobName']}/training_metrics.json\"\n",
    "s3_client.upload_file(Filename='training_metrics.json', Bucket=default_bucket, Key=metrics_s3_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'ModelQuality': {\n",
    "        'Statistics': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f's3://{default_bucket}/{prefix}/{metrics_s3_key}'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_spec ={    \n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\" : [{\n",
    "            \"Image\": training_job_info['AlgorithmSpecification']['TrainingImage'],\n",
    "            \"ModelDataUrl\": training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "        }],\n",
    "        \"SupportedTransformInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedContentTypes\": ['text/csv'],\n",
    "        \"SupportedResponseMIMETypes\": ['text/csv']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# {'ModelDataUrl': }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register second model package to Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageDescription': 'XGBoost classifier with SMOTE',\n",
    "    'ModelApprovalStatus': 'PendingManualApproval',\n",
    "    'ModelMetrics': model_metrics\n",
    "}\n",
    "\n",
    "mp_input_dict.update(inference_spec)\n",
    "mp2_response = sagemaker_boto_client.create_model_package(**mp_input_dict)\n",
    "mp2_arn = mp2_response['ModelPackageArn']\n",
    "%store mp2_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of model package creation¶\n",
    "\n",
    "mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp2_response['ModelPackageArn'])\n",
    "mp_status = mp_info['ModelPackageStatus']\n",
    "\n",
    "while mp_status not in ['Completed', 'Failed']:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp2_response['ModelPackageArn'])\n",
    "    mp_status = mp_info['ModelPackageStatus']\n",
    "    print(f'model package status: {mp_status}')\n",
    "print(f'model package status: {mp_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View both models in the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Bias and Explainability\n",
    "\n",
    "<span style=\"color:red\">**TODO:  more clarify info (including explainability **</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sagemaker_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)\n",
    "\n",
    "bias_report_output_path = f's3://{default_bucket}/{prefix}/clarify-output/bias_2'\n",
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_data_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='LABEL',\n",
    "                                      headers=header,\n",
    "                                      dataset_type='text/csv')\n",
    "\n",
    "model_config = clarify.ModelConfig(model_name=model_2_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')\n",
    "\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[0],\n",
    "                                facet_name='SEX',\n",
    "                                facet_values_or_threshold=[1],\n",
    "                                group_name='AGE'\n",
    "                                )\n",
    "\n",
    "\n",
    "# # uncomment to run clarify job\n",
    "# clarify_processor.run_bias(data_config=bias_data_config,\n",
    "#                            bias_config=bias_config,\n",
    "#                            model_config=model_config,\n",
    "#                            model_predicted_label_config=predictions_config,\n",
    "#                            pre_training_methods='all',\n",
    "#                            post_training_methods='all')\n",
    "\n",
    "# clarify_bias_job_2_name = clarify_processor.latest_job.name\n",
    "# # clarify_bais_job_2_name = 'Clarify-Bias-2021-04-19-18-43-09-582'\n",
    "# %store clarify_bias_job_2_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(Bucket=default_bucket,\n",
    "                        Key=f'{prefix}/clarify-output/bias_2/report.pdf',\n",
    "                        Filename='../outputs/clarify_output/bias_2_report.pdf')\n",
    "print(f'Downloaded clarify report from previous Clarify job: {clarify_bias_job_2_name}')\n",
    "display(\"Click link below to view the Clarify repot.\", FileLink(\"../outputs/clarify_output/bias_2_report.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    baseline=[X_train.median().values[1:].tolist()],\n",
    "    num_samples=100,\n",
    "    agg_method='mean_abs')\n",
    "\n",
    "explainability_output_path = f's3://{default_bucket}/{prefix}/clarify-output/explainability'\n",
    "explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_res_data_uri,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label='LABEL',\n",
    "    headers=header,\n",
    "    dataset_type='text/csv')\n",
    "\n",
    "# # un-comment the code below to run the whole job\n",
    "# clarify_processor.run_explainability(\n",
    "#     data_config=explainability_data_config,\n",
    "#     model_config=model_config,\n",
    "#     explainability_config=shap_config)\n",
    "\n",
    "# clarify_expl_job_name = clarify_processor.latest_job.name\n",
    "# %store clarify_expl_job_name\n",
    "# print(f'Clarify job {clarify_expl_job_name} ran successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3://{default_bucket}/{prefix}/clarify-output/explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'clarify_expl_job_name' in locals():\n",
    "    s3_client.download_file(\n",
    "        Bucket   = default_bucket, \n",
    "        Key      = f'{prefix}/clarify-output/explainability/analysis.json', \n",
    "        Filename = '../outputs/clarify_output/explainability_analysis.json'\n",
    "    )\n",
    "    print(f'Downloaded analysis from previous Clarify job: {clarify_expl_job_name}\\n')\n",
    "else:\n",
    "    print(f'Loading pre-generated analysis file...\\n')\n",
    "\n",
    "with open('../outputs/clarify_output/explainability_analysis.json', 'r') as f:\n",
    "        analysis_result = json.load(f)\n",
    "        \n",
    "shap_values = pd.DataFrame(analysis_result['explanations']['kernel_shap'][\"label0\"])\n",
    "importances = shap_values['global_shap_values'].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n = 10\n",
    "y_pos = np.arange(n)\n",
    "importance_scores = importances.values[:n]\n",
    "y_label = importances.index[:n]\n",
    "ax.barh(y_pos, importance_scores, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(y_label)\n",
    "ax.invert_yaxis()  \n",
    "ax.set_xlabel('SHAP Value (impact on model output)');"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
