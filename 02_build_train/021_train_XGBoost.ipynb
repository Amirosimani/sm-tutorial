{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import clarify\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Set region, boto3 and SageMaker SDK variablesÂ¶\n",
    "\n",
    "#You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "data_prefix                      -> 'sagemaker-tutorial/data'\n",
      "default_bucket                   -> 'sagemaker-us-east-1-367158743199'\n",
      "header                           -> ['LABEL', 'ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', '\n",
      "local_data_dir                   -> '../data'\n",
      "local_processed_path             -> '../data/df_processed.csv'\n",
      "local_raw_path                   -> '../data/dataset.csv'\n",
      "prefix                           -> 'sagemaker-tutorial'\n",
      "s3_raw_data                      -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n"
     ]
    }
   ],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "## Split DataFrame into Train, Validation & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(s3_raw_data)\n",
    "df['LABEL'] = df['LABEL'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'header' (list)\n"
     ]
    }
   ],
   "source": [
    "header = list(df.columns)\n",
    "%store header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'local_processed_path' (str)\n"
     ]
    }
   ],
   "source": [
    "local_data_path = f'{local_data_dir}/df_processed.csv'\n",
    "\n",
    "df.to_csv(local_processed_path)\n",
    "%store local_processed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val = train_test_split(X_test, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_train.to_csv(f'{local_data_dir}/train.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/train.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_data_uri = response\n",
    "%store train_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'validation_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_val.to_csv(f'{local_data_dir}/validation.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/validation.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "validation_data_uri = response\n",
    "%store validation_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_test.to_csv(f'{local_data_dir}/test.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/test.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "test_data_uri = response\n",
    "%store test_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost details**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost hyperparameters details**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hyperparameters' (dict)\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"50\"}\n",
    "\n",
    "%store hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "estimator_output_path = f's3://{default_bucket}/{prefix}/training_jobs'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=hyperparameters,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=estimator_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 02:12:29 Starting - Starting the training job...\n",
      "2021-04-06 02:12:52 Starting - Launching requested ML instancesProfilerReport-1617675149: InProgress\n",
      "......\n",
      "2021-04-06 02:13:53 Starting - Preparing the instances for training......\n",
      "2021-04-06 02:14:58 Downloading - Downloading input data\n",
      "2021-04-06 02:14:58 Training - Downloading the training image......\n",
      "2021-04-06 02:15:53 Uploading - Uploading generated training model\u001b[34m[2021-04-06 02:15:49.944 ip-10-2-83-130.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 4800 rows and 23 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 1200 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.17833#011validation-error:0.17417\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.17792#011validation-error:0.17000\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.17292#011validation-error:0.17083\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.17208#011validation-error:0.17250\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.17396#011validation-error:0.17333\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.17313#011validation-error:0.17417\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.16979#011validation-error:0.17833\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.16875#011validation-error:0.18167\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.16687#011validation-error:0.17750\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.16625#011validation-error:0.17917\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.16583#011validation-error:0.18000\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.16542#011validation-error:0.17667\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.16604#011validation-error:0.17500\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.16562#011validation-error:0.17333\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.16396#011validation-error:0.17500\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.16312#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.16271#011validation-error:0.17083\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.16354#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.16333#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.16312#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.16083#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.16000#011validation-error:0.17250\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.15979#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.15958#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.15833#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.15833#011validation-error:0.17333\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.15812#011validation-error:0.17250\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.15729#011validation-error:0.17000\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.15687#011validation-error:0.17000\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.15625#011validation-error:0.17000\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.15604#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.15583#011validation-error:0.17167\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.15563#011validation-error:0.17333\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.15417#011validation-error:0.17417\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.15313#011validation-error:0.17500\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.15271#011validation-error:0.17583\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.15271#011validation-error:0.17667\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.15188#011validation-error:0.17917\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.15063#011validation-error:0.18000\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.15021#011validation-error:0.18000\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.14896#011validation-error:0.18083\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.14833#011validation-error:0.17917\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.14813#011validation-error:0.17917\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.14792#011validation-error:0.17917\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.14667#011validation-error:0.18000\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.14729#011validation-error:0.18083\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.14646#011validation-error:0.18083\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.14583#011validation-error:0.18333\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.14604#011validation-error:0.18333\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.14333#011validation-error:0.18250\u001b[0m\n",
      "\n",
      "2021-04-06 02:16:13 Completed - Training job completed\n",
      "Training seconds: 75\n",
      "Billable seconds: 75\n",
      "Stored 'training_job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "train_input = TrainingInput(train_data_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_data_uri, content_type=\"text/csv\")\n",
    "\n",
    "# execute the XGBoost training job\n",
    "xgb_estimator.fit({'train': train_input,\n",
    "                   'validation': validation_input\n",
    "                  }\n",
    "                   )\n",
    "\n",
    "training_job_name = xgb_estimator.latest_training_job.job_name\n",
    "%store training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-2021-04-06-02-12-29-010-model'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f'{training_job_name}-model'\n",
    "model = xgb_estimator.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "\n",
    "sagemaker_session.create_model(model_name,\n",
    "                     sagemaker_role,\n",
    "                     container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify\n",
    "Now that you have your model set up. Letâs say hello to SageMaker Clarify!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sagemaker_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Bias\n",
    "\n",
    "SageMaker Clarify helps you detect possible pre- and post-training biases using a variety of metrics. \n",
    "\n",
    "A `DataConfig` object communicates some basic information about data I/O to SageMaker Clarify. We specify where to find the input dataset, where to store the output, the target column (`label`), the header names, and the dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_output_path = 's3://{}/{}/clarify-bias'.format(default_bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_data_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='LABEL',\n",
    "                                      headers=header,\n",
    "                                      dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelConfig` object communicates information about your trained model. To avoid additional traffic to your production models, SageMaker Clarify sets up and tears down a dedicated endpoint when processing. * instance_type and instance_count specify your preferred instance type and instance count used to run your model on during SageMaker Clarifyâs processing. The testing dataset is small so a single standard instance is good enough to run this example. If your have a large complex dataset, you may want to use a better instance type to speed up, or add more instances to enable Spark parallelization. * accept_type denotes the endpoint response payload format, and content_type denotes the payload format of request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelPredictedLabelConfig` provides information on the format of your predictions. XGBoost model outputs probabilities of samples, so SageMaker Clarify invokes the endpoint then uses `probability_threshold` to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value 1 and below or equal as label value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing BiasConfig\n",
    "\n",
    "SageMaker Clarify also needs information on what the sensitive columns (`facets`) are, what the sensitive features (`facet_values_or_threshold`) may be, and what the desirable outcomes are (`label_values_or_threshold`). SageMaker Clarify can handle both categorical and continuous data for `facet_values_or_threshold` and for `label_values_or_threshold`. In this case we are using categorical data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify this information in the BiasConfig API. Here we use `SEX` as the sensitive group.\n",
    "\n",
    "group_name is used to form subgroups for the measurement of Conditional Demographic Disparity in Labels (CDDL) and Conditional Demographic Disparity in Predicted Labels (CDDPL) with regards to Simpsonâs paradox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[1],\n",
    "                                facet_name='SEX',\n",
    "                                facet_values_or_threshold=[0],\n",
    "                                group_name='AGE'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  PRETRIANING BIAS WITH WRANGLER**</span>\n",
    "\n",
    "\n",
    "refer to smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-training Bias\n",
    "\n",
    "Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "Unbiased training data (as determined by concepts of fairness measured by bias metric) may still result in biased model predictions after training. Whether this occurs depends on several factors including hyperparameter choices.\n",
    "\n",
    "You can run these options separately with `run_pre_training_bias()` and `run_post_training_bias()` or at the same time with `run_bias()` as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Bias-2021-04-06-02-18-03-748\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/data/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/clarify-bias/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/clarify-bias', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...........................\u001b[34mINFO:sagemaker-clarify-processing:Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis config path: /opt/ml/processing/input/config\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is algo-1.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is the leader.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Dataset uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Dataset type: text/csv\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Creating endpoint-config with name sagemaker-clarify-endpoint-config-1617675745-5741\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Creating endpoint sagemaker-clarify-endpoint-1617675745-3b2e\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:======================================\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Calculating post-training bias metrics\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:======================================\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Getting predictions from the endpoint\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Checking endpoint status\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Endpoint is in service after 421 seconds\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Prediction batch size is initialized with 76725\u001b[0m\n",
      "\u001b[34mINFO:analyzer.prediction_util:We assume a prediction above 0.500 indicates 1 and below or equal indicates 0.\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:AD metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 224, in AD\n",
      "    raise ValueError(\"Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DAR metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 179, in DAR\n",
      "    dar, _ = common.DLR(feature, sensitive_facet_index, positive_label_index, positive_predicted_label_index)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/common.py\", line 220, in DLR\n",
      "    raise ValueError(\"DLR: Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: DLR: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DCA metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 96, in DCA\n",
      "    dca, _ = common.DCO(feature, sensitive_facet_index, positive_label_index, positive_predicted_label_index)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/common.py\", line 166, in DCO\n",
      "    raise ValueError(\"DCO: Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: DCO: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DCR metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 116, in DCR\n",
      "    _, dcr = common.DCO(feature, sensitive_facet_index, positive_label_index, positive_predicted_label_index)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/common.py\", line 166, in DCO\n",
      "    raise ValueError(\"DCO: Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: DCO: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DI metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 75, in DI\n",
      "    raise ValueError(\"Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DPPL metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 41, in DPPL\n",
      "    return common.DPL(feature, sensitive_facet_index, positive_predicted_label_index)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/common.py\", line 62, in DPL\n",
      "    raise ValueError(\"Facet set is empty.\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty.\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DRR metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 199, in DRR\n",
      "    _, drr = common.DLR(feature, sensitive_facet_index, positive_label_index, positive_predicted_label_index)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/common.py\", line 220, in DLR\n",
      "    raise ValueError(\"DLR: Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: DLR: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:FT metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 355, in FT\n",
      "    raise ValueError(\"Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:RD metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 141, in RD\n",
      "    raise ValueError(\"Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:TE metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/posttraining.py\", line 302, in TE\n",
      "    raise ValueError(\"Facet set is empty\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Stop using endpoint: sagemaker-clarify-endpoint-1617675745-3b2e\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint configuration with name: sagemaker-clarify-endpoint-config-1617675745-5741\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint with name: sagemaker-clarify-endpoint-1617675745-3b2e\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Model endpoint delivered 1.99013 requests per second and a total of 1 requests over 1 seconds\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Delivered 1 predict calls with a total of 4800 examples.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Stop using endpoint: None\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Delivered 1 predict calls with a total of 4800 examples.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:=====================================\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Calculating pre-training bias metrics\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:=====================================\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0004166666666666667\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:CI metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 53, in CI\n",
      "    raise ValueError(\"CI: facet set is empty. Check that x[facet] has non-zero length.\")\u001b[0m\n",
      "\u001b[34mValueError: CI: facet set is empty. Check that x[facet] has non-zero length.\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:DPL metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 71, in DPL\n",
      "    return common.DPL(feature, sensitive_facet_index, positive_label_index)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/common.py\", line 62, in DPL\n",
      "    raise ValueError(\"Facet set is empty.\")\u001b[0m\n",
      "\u001b[34mValueError: Facet set is empty.\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:JS metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 114, in JS\n",
      "    raise ValueError(\"No instance of common facet found, dataset may be too small\")\u001b[0m\n",
      "\u001b[34mValueError: No instance of common facet found, dataset may be too small\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:KL metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 91, in KL\n",
      "    raise ValueError(\"No instance of common facet found, dataset may be too small\")\u001b[0m\n",
      "\u001b[34mValueError: No instance of common facet found, dataset may be too small\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:KS metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 175, in KS\n",
      "    return LP_norm(label, sensitive_facet_index, np.inf)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 141, in LP_norm\n",
      "    raise ValueError(\"No instance of common facet found, dataset may be too small\")\u001b[0m\n",
      "\u001b[34mValueError: No instance of common facet found, dataset may be too small\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:LP metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 132, in LP\n",
      "    return LP_norm(label, sensitive_facet_index, 2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 141, in LP_norm\n",
      "    raise ValueError(\"No instance of common facet found, dataset may be too small\")\u001b[0m\n",
      "\u001b[34mValueError: No instance of common facet found, dataset may be too small\u001b[0m\n",
      "\u001b[34mERROR:smclarify.bias.report:TVD metrics failed\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 292, in _categorical_metric_call_wrapper\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/__init__.py\", line 26, in call_metric\n",
      "    return metric(**{key: kwargs[key] for key in inspect.signature(metric).parameters.keys()})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 158, in TVD\n",
      "    Lp_res = LP_norm(label, sensitive_facet_index, 1)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/metrics/pretraining.py\", line 141, in LP_norm\n",
      "    raise ValueError(\"No instance of common facet found, dataset may be too small\")\u001b[0m\n",
      "\u001b[34mValueError: No instance of common facet found, dataset may be too small\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 277759 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34mINFO:analyzer.report:HTML report '/opt/ml/processing/output/report.html' generated successfully.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.report:PDF report '/opt/ml/processing/output/report.pdf' generated successfully.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Collected analyses: \u001b[0m\n",
      "\u001b[34m{\n",
      "    \"version\": \"1.0\",\n",
      "    \"post_training_bias_metrics\": {\n",
      "        \"label\": \"LABEL\",\n",
      "        \"facets\": {\n",
      "            \"SEX\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"0\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"AD\",\n",
      "                            \"description\": \"Accuracy Difference (AD)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"CDDPL\",\n",
      "                            \"description\": \"Conditional Demographic Disparity in Predicted Labels (CDDPL)\",\n",
      "                            \"value\": 0.0\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DAR\",\n",
      "                            \"description\": \"Difference in Acceptance Rates (DAR)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"DLR: Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DCA\",\n",
      "                            \"description\": \"Difference in Conditional Acceptance (DCA)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"DCO: Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DCR\",\n",
      "                            \"description\": \"Difference in Conditional Rejection (DCR)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"DCO: Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DI\",\n",
      "                            \"description\": \"Disparate Impact (DI)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DPPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Predicted Labels (DPPL)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DRR\",\n",
      "                            \"description\": \"Difference in Rejection Rates (DRR)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"DLR: Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"FT\",\n",
      "                            \"description\": \"Flip Test (FT)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"RD\",\n",
      "                            \"description\": \"Recall Difference (RD)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"TE\",\n",
      "                            \"description\": \"Treatment Equality (TE)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"1\"\n",
      "    },\n",
      "    \"pre_training_bias_metrics\": {\n",
      "        \"label\": \"LABEL\",\n",
      "        \"facets\": {\n",
      "            \"SEX\": [\n",
      "                {\n",
      "                    \"value_or_threshold\": \"0\",\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"CDDL\",\n",
      "                            \"description\": \"Conditional Demographic Disparity in Labels (CDDL)\",\n",
      "                            \"value\": 0.0\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"CI\",\n",
      "                            \"description\": \"Class Imbalance (CI)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"CI: facet set is empty. Check that x[facet] has non-zero length.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"DPL\",\n",
      "                            \"description\": \"Difference in Positive Proportions in Labels (DPL)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"Facet set is empty.\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"JS\",\n",
      "                            \"description\": \"Jensen-Shannon Divergence (JS)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"No instance of common facet found, dataset may be too small\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"KL\",\n",
      "                            \"description\": \"Kullback-Liebler Divergence (KL)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"No instance of common facet found, dataset may be too small\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"KS\",\n",
      "                            \"description\": \"Kolmogorov-Smirnov Distance (KS)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"No instance of common facet found, dataset may be too small\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"LP\",\n",
      "                            \"description\": \"L-p Norm (LP)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"No instance of common facet found, dataset may be too small\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"TVD\",\n",
      "                            \"description\": \"Total Variation Distance (TVD)\",\n",
      "                            \"value\": null,\n",
      "                            \"error\": \"No instance of common facet found, dataset may be too small\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"label_value_or_threshold\": \"1\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:analyzer.system_util:exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\u001b[34m-------!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clarify_processor.run_bias(data_config=bias_data_config,\n",
    "                           bias_config=bias_config,\n",
    "                           model_config=model_config,\n",
    "                           model_predicted_label_config=predictions_config,\n",
    "                           pre_training_methods='all',\n",
    "                           post_training_methods='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TODO:  SCREENSHOTS OF BIAS REPORT IN STUDIO**</span>\n",
    "\n",
    "https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Lineage\n",
    "\n",
    "Amazon SageMaker ML Lineage Tracking creates and stores information about the steps of a machine learning (ML) workflow from data preparation to model deployment. With the tracking information you can reproduce the workflow steps, track model and dataset lineage, and establish model governance and audit standards. With SageMaker Lineage Tracking data scientists and model builders can do the following:\n",
    "\n",
    "* Keep a running history of model discovery experiments.\n",
    "* Establish model governance by tracking model lineage artifacts for auditing and compliance verification.\n",
    "* Clone and rerun workflows to experiment with what-if scenarios while developing models.\n",
    "* Share a workflow that colleagues can reproduce and enhance (for example, while collaborating on solving a business problem).\n",
    "* Clone and rerun workflows with additional debugging or logging routines, or new input variations for troubleshooting issues in production models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:367158743199:artifact/46e81ac5bb720131c95259d4f2325499\n"
     ]
    }
   ],
   "source": [
    "training_data_s3_uri = training_job_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=training_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    training_data_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {training_data_artifact.artifact_arn}')\n",
    "else:\n",
    "    training_data_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainingData',\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type='Dataset',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:367158743199:artifact/8fba0a933c53b2a735df0092e7e01757\n"
     ]
    }
   ],
   "source": [
    "trained_model_s3_uri = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=trained_model_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    model_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {model_artifact.artifact_arn}')\n",
    "else:\n",
    "    model_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainedModel',\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type='Model',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {model_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set artifact associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(TrialComponentName=training_job_name+'-aws-training-job')\n",
    "trial_component_arn = trial_component['TrialComponentArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association already exists with DataSet\n"
     ]
    }
   ],
   "source": [
    "# input artifacts\n",
    "input_artifacts = [training_data_artifact]\n",
    "\n",
    "for a in input_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='ContributedTo',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCEESFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association with Model: SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "# output artifacts\n",
    "output_artifacts = [model_artifact]\n",
    "\n",
    "for a in output_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='Produced',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCESSFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deposit Model and Lineage in SageMaker Model Registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Package Group\n",
    "\n",
    "A Model Package Groups holds multiple versions or iterations of a model. Though it is not required to create them for every model in the registry, they help organize various models which all have the same purpose and provide autiomatic versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mpg_name' (str)\n",
      "Model Package Group name: sagemaker-tutorial\n"
     ]
    }
   ],
   "source": [
    "mpg_name = prefix\n",
    "%store mpg_name\n",
    "print(f'Model Package Group name: {mpg_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageGroupDescription': 'Credit Defualt Prediction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing Model Package Group: sagemaker-tutorial\n"
     ]
    }
   ],
   "source": [
    "matching_mpg = sagemaker_boto_client.list_model_package_groups(NameContains=mpg_name)['ModelPackageGroupSummaryList']\n",
    "\n",
    "if matching_mpg:\n",
    "    print(f'Using existing Model Package Group: {mpg_name}')\n",
    "else:\n",
    "    mpg_response = sagemaker_boto_client.create_model_package_group(**mpg_input_dict)\n",
    "    print(f'Create Model Package Group {mpg_name}: SUCCESSFUL')\n",
    "    %store mpg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and upload a metrics report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {'classification_metrics': {}}\n",
    "for metric in training_job_info['FinalMetricDataList']:\n",
    "    stat = {metric['MetricName']: {'value': metric['Value']}}\n",
    "    model_metrics_report['classification_metrics'].update(stat)\n",
    "    \n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "    \n",
    "metrics_s3_key = f\"{prefix}/training_jobs/{training_job_info['TrainingJobName']}/training_metrics.json\"\n",
    "s3_client.upload_file(Filename='training_metrics.json', Bucket=default_bucket, Key=metrics_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'ModelQuality': {\n",
    "        'Statistics': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f's3://{default_bucket}/{prefix}/{metrics_s3_key}'\n",
    "        }\n",
    "    },\n",
    "    'Bias': {\n",
    "        'Report': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f'{bias_report_output_path}/analysis.json'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the inference spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_spec ={    \n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\" : [{\n",
    "            \"Image\": training_job_info['AlgorithmSpecification']['TrainingImage'],\n",
    "            \"ModelDataUrl\": training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "        }],\n",
    "        \"SupportedTransformInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedContentTypes\": ['text/csv'],\n",
    "        \"SupportedResponseMIMETypes\": ['text/csv']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# {'ModelDataUrl': }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
    "    'ModelApprovalStatus': 'PendingManualApproval',\n",
    "    'ModelMetrics': model_metrics\n",
    "}\n",
    "\n",
    "mp_input_dict.update(inference_spec)\n",
    "mp1_response = sagemaker_boto_client.create_model_package(**mp_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model package status: Completed\n"
     ]
    }
   ],
   "source": [
    "mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "mp_status = mp_info['ModelPackageStatus']\n",
    "\n",
    "while mp_status not in ['Completed', 'Failed']:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "    mp_status = mp_info['ModelPackageStatus']\n",
    "    print(f'model package status: {mp_status}')\n",
    "print(f'model package status: {mp_status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ModelPackageGroupName': 'sagemaker-tutorial',\n",
       "  'ModelPackageVersion': 4,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:367158743199:model-package/sagemaker-tutorial/4',\n",
       "  'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 6, 2, 32, 39, 455000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'PendingManualApproval'},\n",
       " {'ModelPackageGroupName': 'sagemaker-tutorial',\n",
       "  'ModelPackageVersion': 3,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:367158743199:model-package/sagemaker-tutorial/3',\n",
       "  'ModelPackageDescription': 'XGBoost classifier with SMOTE',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 2, 20, 16, 49, 511000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'Approved'},\n",
       " {'ModelPackageGroupName': 'sagemaker-tutorial',\n",
       "  'ModelPackageVersion': 2,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:367158743199:model-package/sagemaker-tutorial/2',\n",
       "  'ModelPackageDescription': 'XGBoost classifier with SMOTE',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 2, 2, 32, 30, 40000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'Approved'},\n",
       " {'ModelPackageGroupName': 'sagemaker-tutorial',\n",
       "  'ModelPackageVersion': 1,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:367158743199:model-package/sagemaker-tutorial/1',\n",
       "  'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 1, 20, 59, 31, 765000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'PendingManualApproval'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view model package in registry\n",
    "sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
