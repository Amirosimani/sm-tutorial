{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import clarify\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Set region, boto3 and SageMaker SDK variablesÂ¶\n",
    "\n",
    "#You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "clarify_data_uri                -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n",
      "data_prefix                     -> 'sagemaker-tutorial/data'\n",
      "default_bucket                  -> 'sagemaker-us-east-1-367158743199'\n",
      "feature_group_name              -> 'FG-flow-sm-tutorial-31-16-16-17-9f41d66b'\n",
      "hyperparameters                 -> {'max_depth': '5', 'eta': '0.2', 'gamma': '4', 'mi\n",
      "model_data                      -> 's3://sagemaker-us-east-1-367158743199/tf2-resnet-\n",
      "prefix                          -> 'sagemaker-tutorial'\n",
      "s3_raw_data                     -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n",
      "s3_train_data                   -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n",
      "s3_validation_data              -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n",
      "test_data_uri                   -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n",
      "train_data_uri                  -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n",
      "training_job_1_name             -> 'sagemaker-xgboost-2021-04-01-18-55-54-829'\n",
      "validation_data_uri             -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n"
     ]
    }
   ],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from offline feature store\n",
    "\n",
    "Feature Store provides offline storage for feature values in your S3 bucket. Your data is stored in your S3 bucket using a prefixing scheme based on event time. The offline store is an append-only store, enabling Feature Store to maintain a historical record of all feature values. Data is stored in the offline store in Parquet format for optimized storage and query access.\n",
    "\n",
    "You can query, explore, and visualize features using Data Wrangler from Amazon SageMaker Studio.  Feature Store supports combining data to produce, train, validate, and test data sets, and allows you to extract data at different points in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  THE CODE NEEDS TO CHANGE**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', \n",
    "#                                            region_name=region\n",
    "#                                           )\n",
    "\n",
    "# feature_store_session = Session(\n",
    "#     boto_session=boto_session,\n",
    "#     sagemaker_client=sagemaker_boto_client,\n",
    "#     sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    "# )\n",
    "\n",
    "# offline_feature_store_bucket = f's3://{default_bucket}/{account_id}/sagemaker/{region}/offline-store/{feature_group_name}/data/year=2021/month=03/day=31/hour=16/'\n",
    "# offline_feature_store_bucket\n",
    "\n",
    "# !aws s3 cp $offline_feature_store_bucket ../sm-tutorial/02_build_train/ --recursive\n",
    "\n",
    "# # offline_feature_store_bucket = f's3://{default_bucket}/'\n",
    "# fg_prefix = f'sagemaker/{region}/offline-store/{feature_group_name}/data/'\n",
    "# s3_client.list_objects_v2(Bucket=default_bucket,\n",
    "#                          Prefix=fg_prefix,\n",
    "#                          Delimiter='/')\n",
    "\n",
    "# def download_all_objects_in_folder():\n",
    "#     s3_resource = boto3.resource('s3')\n",
    "#     my_bucket = s3_resource.Bucket(default_bucket)\n",
    "#     objects = my_bucket.objects.filter(Prefix=offline_feature_prefix)\n",
    "#     for obj in objects:\n",
    "#         path, filename = os.path.split(obj.key)\n",
    "#         my_bucket.download_file(obj.key, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/20210331T162204Z_ATxVKv9V8rL9hJyQ.parquet to ../sm-tutorial/02_build_train/processed_data/parquet/20210331T162204Z_ATxVKv9V8rL9hJyQ.parquet\n",
      "download: s3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/20210331T162204Z_BVs0QiuqNaVyrXTY.parquet to ../sm-tutorial/02_build_train/processed_data/parquet/20210331T162204Z_BVs0QiuqNaVyrXTY.parquet\n",
      "download: s3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/20210331T162204Z_KnPgBMRO3yEo3BP3.parquet to ../sm-tutorial/02_build_train/processed_data/parquet/20210331T162204Z_KnPgBMRO3yEo3BP3.parquet\n"
     ]
    }
   ],
   "source": [
    "file_names = ['20210331T162204Z_ATxVKv9V8rL9hJyQ.parquet',\n",
    "             '20210331T162204Z_BVs0QiuqNaVyrXTY.parquet',\n",
    "             '20210331T162204Z_KnPgBMRO3yEo3BP3.parquet\t']\n",
    "\n",
    "local_processed_data = '../sm-tutorial/02_build_train/processed_data/parquet/'\n",
    "for f in file_names:\n",
    "    s3_path = f's3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/{f}'\n",
    "\n",
    "    ! aws s3 cp $s3_path $local_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../sm-tutorial/02_build_train/processed_data/parquet/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "def join_parquet_files(dir_path=local_processed_data):\n",
    "    all_files = os.listdir(dir_path)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for f in all_files:\n",
    "        full_path = os.path.join(dir_path, f)\n",
    "        df_partial = pq.read_table(full_path).to_pandas()\n",
    "        df = pd.concat([df, df_partial], axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = join_parquet_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataFrame into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature store created columns\n",
    "df_processed = df_processed.drop(columns=['ID', 'EVENT_TIME', 'write_time', 'api_invocation_time', 'is_deleted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['LABEL'] = df_processed['LABEL'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df_processed, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val = train_test_split(X_test, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_train.to_csv(f'{local_processed_data}/train.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_processed_data}/train.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_data_uri = response\n",
    "%store train_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the same training file with header for clarify\n",
    "# X_train.to_csv(f'{local_processed_data}/train.csv', header=True, index=False)\n",
    "\n",
    "# response = sagemaker_session.upload_data(f'{local_processed_data}/train.csv',\n",
    "#                                          bucket=default_bucket, \n",
    "#                                          key_prefix=data_prefix)\n",
    "# clarify_data_uri = response\n",
    "# %store clarify_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'validation_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_val.to_csv(f'{local_processed_data}/validation.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_processed_data}/validation.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "validation_data_uri = response\n",
    "%store validation_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_test.to_csv(f'{local_processed_data}/test.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_processed_data}/test.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "test_data_uri = response\n",
    "%store test_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost details**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost hyperparameters details**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hyperparameters' (dict)\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"50\"}\n",
    "\n",
    "%store hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "estimator_output_path = f's3://{default_bucket}/{prefix}/training_jobs'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=hyperparameters,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=estimator_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 19:55:41 Starting - Starting the training job...\n",
      "2021-04-01 19:56:04 Starting - Launching requested ML instancesProfilerReport-1617306941: InProgress\n",
      "......\n",
      "2021-04-01 19:57:04 Starting - Preparing the instances for training.........\n",
      "2021-04-01 19:58:35 Downloading - Downloading input data\n",
      "2021-04-01 19:58:35 Training - Downloading the training image.....\u001b[34m[2021-04-01 19:59:20.090 ip-10-0-235-37.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 1354 rows and 23 columns\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.16691\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.15140\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.15362\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.15140\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.14919\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.15214\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.14697\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.14845\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.14845\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.14845\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.14623\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.14550\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.14771\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.14476\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.14254\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.14254\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.14328\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.14254\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.14180\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.14254\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.13959\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.13737\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.13442\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.13442\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.13885\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.13737\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.13589\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.13663\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.13220\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.13368\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.13294\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.13220\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.13072\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.12998\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.13072\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.13220\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.12703\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.12851\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.12555\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.12555\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.12555\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.12408\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.12481\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.12408\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.12334\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.12260\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.12038\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.12112\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.12112\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.12112\u001b[0m\n",
      "\n",
      "2021-04-01 19:59:32 Uploading - Uploading generated training model\n",
      "2021-04-01 19:59:32 Completed - Training job completed\n",
      "Training seconds: 74\n",
      "Billable seconds: 74\n",
      "Stored 'training_job_1_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "train_input = TrainingInput(train_data_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_data_uri, content_type=\"text/csv\")\n",
    "\n",
    "# execute the XGBoost training job\n",
    "xgb_estimator.fit({'train': train_input,\n",
    "#                    'validation': validation_input\n",
    "                  }\n",
    "                   )\n",
    "\n",
    "training_job_name = xgb_estimator.latest_training_job.job_name\n",
    "%store training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-2021-04-01-19-55-41-144'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-2021-04-01-19-55-41-144-model'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f'{training_job_name}-model'\n",
    "model = xgb_estimator.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "\n",
    "sagemaker_session.create_model(model_name,\n",
    "                     sagemaker_role,\n",
    "                     container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify\n",
    "Now that you have your model set up. Letâs say hello to SageMaker Clarify!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sagemaker_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Bias\n",
    "\n",
    "SageMaker Clarify helps you detect possible pre- and post-training biases using a variety of metrics. \n",
    "\n",
    "A `DataConfig` object communicates some basic information about data I/O to SageMaker Clarify. We specify where to find the input dataset, where to store the output, the target column (`label`), the header names, and the dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_output_path = 's3://{}/{}/clarify-bias'.format(default_bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_data_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='LABEL',\n",
    "                                      headers=df_processed.columns.to_list(),\n",
    "                                      dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelConfig` object communicates information about your trained model. To avoid additional traffic to your production models, SageMaker Clarify sets up and tears down a dedicated endpoint when processing. * instance_type and instance_count specify your preferred instance type and instance count used to run your model on during SageMaker Clarifyâs processing. The testing dataset is small so a single standard instance is good enough to run this example. If your have a large complex dataset, you may want to use a better instance type to speed up, or add more instances to enable Spark parallelization. * accept_type denotes the endpoint response payload format, and content_type denotes the payload format of request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelPredictedLabelConfig` provides information on the format of your predictions. XGBoost model outputs probabilities of samples, so SageMaker Clarify invokes the endpoint then uses `probability_threshold` to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value 1 and below or equal as label value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing BiasConfig\n",
    "\n",
    "SageMaker Clarify also needs information on what the sensitive columns (`facets`) are, what the sensitive features (`facet_values_or_threshold`) may be, and what the desirable outcomes are (`label_values_or_threshold`). SageMaker Clarify can handle both categorical and continuous data for `facet_values_or_threshold` and for `label_values_or_threshold`. In this case we are using categorical data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify this information in the BiasConfig API. Here we use `SEX` as the sensitive group.\n",
    "\n",
    "group_name is used to form subgroups for the measurement of Conditional Demographic Disparity in Labels (CDDL) and Conditional Demographic Disparity in Predicted Labels (CDDPL) with regards to Simpsonâs paradox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[1],\n",
    "                                facet_name='SEX',\n",
    "                                facet_values_or_threshold=[0],\n",
    "                                group_name='AGE'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  PRETRIANING BIAS WITH WRANGLER**</span>\n",
    "\n",
    "\n",
    "refer to smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-training Bias\n",
    "\n",
    "Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "Unbiased training data (as determined by concepts of fairness measured by bias metric) may still result in biased model predictions after training. Whether this occurs depends on several factors including hyperparameter choices.\n",
    "\n",
    "You can run these options separately with `run_pre_training_bias()` and `run_post_training_bias()` or at the same time with `run_bias()` as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Bias-2021-04-01-19-59-54-916\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/data/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/Clarify-Bias-2021-04-01-19-59-54-916/input/analysis_config/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/clarify-bias', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................\u001b[34mINFO:sagemaker-clarify-processing:Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis config path: /opt/ml/processing/input/config\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is algo-1.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is the leader.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Dataset uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Dataset type: text/csv\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Creating endpoint-config with name sagemaker-clarify-endpoint-config-1617307462-9659\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Creating endpoint sagemaker-clarify-endpoint-1617307462-1a6d\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:======================================\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Calculating post-training bias metrics\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:======================================\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Getting predictions from the endpoint\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Checking endpoint status\u001b[0m\n",
      "\n",
      "\u001b[34mINFO:analyzer.predictor:Endpoint is in service after 481 seconds\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Prediction batch size is initialized with 49539\u001b[0m\n",
      "\u001b[34mINFO:analyzer.prediction_util:We assume a prediction above 0.500 indicates 1 and below or equal indicates 0.\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0014771048744460858\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0014771048744460858\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0014771048744460858\u001b[0m\n",
      "\u001b[34mINFO:smclarify.bias.metrics.common:data uniqueness fraction: 0.0014771048744460858\u001b[0m\n",
      "\u001b[34mINFO:analyzer.system_util:exit_message: Customer Error: Predicted Label Column series datatype is not the same as Label Column series\u001b[0m\n",
      "\u001b[34mERROR:analyzer.system_util:Errors occurred when analyzing your data. Please check CloudWatch logs for more details.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/analyzer/analysis_driver.py\", line 279, in main\n",
      "    violations: int = run()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/analyzer/analysis_driver.py\", line 192, in run\n",
      "    summary = run_pandas(configs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/analyzer/analysis_driver.py\", line 130, in run_pandas\n",
      "    predicted_labels=predicted_labels,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/analyzer/bias_analyzer.py\", line 93, in analyze\n",
      "    predicted_labels=predicted_labels,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/analyzer/posttraining_bias_analyzer.py\", line 48, in generate_bias_report\n",
      "    group_variable=group_variable,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 398, in bias_report\n",
      "    positive_label_values=label_column.positive_label_values,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/smclarify/bias/report.py\", line 181, in _positive_predicted_index\n",
      "    raise ValueError(\"Predicted Label Column series datatype is not the same as Label Column series\")\u001b[0m\n",
      "\u001b[34mValueError: Predicted Label Column series datatype is not the same as Label Column series\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint configuration with name: sagemaker-clarify-endpoint-config-1617307462-9659\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint with name: sagemaker-clarify-endpoint-1617307462-1a6d\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor:Model endpoint delivered 2.93407 requests per second and a total of 1 requests over 0 seconds\u001b[0m\n",
      "\u001b[34m--------!\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job Clarify-Bias-2021-04-01-19-59-54-916: Failed. Reason: ClientError: Predicted Label Column series datatype is not the same as Label Column series\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-25a797383b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mmodel_predicted_label_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0mpre_training_methods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                            post_training_methods='all')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/clarify.py\u001b[0m in \u001b[0;36mrun_bias\u001b[0;34m(self, data_config, bias_config, model_config, model_predicted_label_config, pre_training_methods, post_training_methods, wait, logs, job_name, kms_key)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjob_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0mjob_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_from_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Clarify-Bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     def run_explainability(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/clarify.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, data_config, analysis_config, wait, logs, job_name, kms_key)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             )\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extend_processing_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=W0613\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \"\"\"\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3777\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ProcessingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3265\u001b[0m                 ),\n\u001b[1;32m   3266\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3267\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3268\u001b[0m             )\n\u001b[1;32m   3269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job Clarify-Bias-2021-04-01-19-59-54-916: Failed. Reason: ClientError: Predicted Label Column series datatype is not the same as Label Column series\n"
     ]
    }
   ],
   "source": [
    "clarify_processor.run_bias(data_config=bias_data_config,\n",
    "                           bias_config=bias_config,\n",
    "                           model_config=model_config,\n",
    "                           model_predicted_label_config=predictions_config,\n",
    "                           pre_training_methods='all',\n",
    "                           post_training_methods='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TODO:  SCREENSHOTS OF BIAS REPORT IN STUDIO**</span>\n",
    "\n",
    "https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Lineage\n",
    "\n",
    "Amazon SageMaker ML Lineage Tracking creates and stores information about the steps of a machine learning (ML) workflow from data preparation to model deployment. With the tracking information you can reproduce the workflow steps, track model and dataset lineage, and establish model governance and audit standards. With SageMaker Lineage Tracking data scientists and model builders can do the following:\n",
    "\n",
    "* Keep a running history of model discovery experiments.\n",
    "* Establish model governance by tracking model lineage artifacts for auditing and compliance verification.\n",
    "* Clone and rerun workflows to experiment with what-if scenarios while developing models.\n",
    "* Share a workflow that colleagues can reproduce and enhance (for example, while collaborating on solving a business problem).\n",
    "* Clone and rerun workflows with additional debugging or logging routines, or new input variations for troubleshooting issues in production models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:367158743199:artifact/46e81ac5bb720131c95259d4f2325499\n"
     ]
    }
   ],
   "source": [
    "training_data_s3_uri = training_job_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=training_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    training_data_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {training_data_artifact.artifact_arn}')\n",
    "else:\n",
    "    training_data_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainingData',\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type='Dataset',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing artifact: arn:aws:sagemaker:us-east-1:367158743199:artifact/b1877c142f08be8fbd8abe259c0051c1\n"
     ]
    }
   ],
   "source": [
    "trained_model_s3_uri = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=trained_model_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    model_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {model_artifact.artifact_arn}')\n",
    "else:\n",
    "    model_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainedModel',\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type='Model',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {model_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set artifact associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(TrialComponentName=training_job_1_name+'-aws-training-job')\n",
    "trial_component_arn = trial_component['TrialComponentArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association already exists with DataSet\n"
     ]
    }
   ],
   "source": [
    "# input artifacts\n",
    "input_artifacts = [training_data_artifact]\n",
    "\n",
    "for a in input_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='ContributedTo',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCEESFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association with Model: SUCCESSFUL\n"
     ]
    }
   ],
   "source": [
    "# output artifacts\n",
    "output_artifacts = [model_artifact]\n",
    "\n",
    "for a in output_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='Produced',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCESSFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deposit Model and Lineage in SageMaker Model Registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Package Group\n",
    "\n",
    "A Model Package Groups holds multiple versions or iterations of a model. Though it is not required to create them for every model in the registry, they help organize various models which all have the same purpose and provide autiomatic versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'mpg_name' (str)\n",
      "Model Package Group name: sagemaker-tutorial\n"
     ]
    }
   ],
   "source": [
    "mpg_name = prefix\n",
    "%store mpg_name\n",
    "print(f'Model Package Group name: {mpg_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageGroupDescription': 'Credit Defualt Prediction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Model Package Group sagemaker-tutorial: SUCCESSFUL\n",
      "Stored 'mpg_name' (str)\n"
     ]
    }
   ],
   "source": [
    "matching_mpg = sagemaker_boto_client.list_model_package_groups(NameContains=mpg_name)['ModelPackageGroupSummaryList']\n",
    "\n",
    "if matching_mpg:\n",
    "    print(f'Using existing Model Package Group: {mpg_name}')\n",
    "else:\n",
    "    mpg_response = sagemaker_boto_client.create_model_package_group(**mpg_input_dict)\n",
    "    print(f'Create Model Package Group {mpg_name}: SUCCESSFUL')\n",
    "    %store mpg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and upload a metrics report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {'classification_metrics': {}}\n",
    "for metric in training_job_info['FinalMetricDataList']:\n",
    "    stat = {metric['MetricName']: {'value': metric['Value']}}\n",
    "    model_metrics_report['classification_metrics'].update(stat)\n",
    "    \n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "    \n",
    "metrics_s3_key = f\"{prefix}/training_jobs/{training_job_info['TrainingJobName']}/training_metrics.json\"\n",
    "s3_client.upload_file(Filename='training_metrics.json', Bucket=default_bucket, Key=metrics_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'ModelQuality': {\n",
    "        'Statistics': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f's3://{default_bucket}/{prefix}/{metrics_s3_key}'\n",
    "        }\n",
    "    },\n",
    "    'Bias': {\n",
    "        'Report': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f'{bias_report_output_path}/analysis.json'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the inference spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_spec ={    \n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\" : [{\n",
    "            \"Image\": training_job_info['AlgorithmSpecification']['TrainingImage'],\n",
    "            \"ModelDataUrl\": training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "        }],\n",
    "        \"SupportedTransformInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedContentTypes\": ['text/csv'],\n",
    "        \"SupportedResponseMIMETypes\": ['text/csv']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# {'ModelDataUrl': }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
    "    'ModelApprovalStatus': 'PendingManualApproval',\n",
    "    'ModelMetrics': model_metrics\n",
    "}\n",
    "\n",
    "mp_input_dict.update(inference_spec)\n",
    "mp1_response = sagemaker_boto_client.create_model_package(**mp_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model package status: Completed\n"
     ]
    }
   ],
   "source": [
    "mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "mp_status = mp_info['ModelPackageStatus']\n",
    "\n",
    "while mp_status not in ['Completed', 'Failed']:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "    mp_status = mp_info['ModelPackageStatus']\n",
    "    print(f'model package status: {mp_status}')\n",
    "print(f'model package status: {mp_status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ModelPackageGroupName': 'sagemaker-tutorial',\n",
       "  'ModelPackageVersion': 1,\n",
       "  'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:367158743199:model-package/sagemaker-tutorial/1',\n",
       "  'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
       "  'CreationTime': datetime.datetime(2021, 4, 1, 20, 59, 31, 765000, tzinfo=tzlocal()),\n",
       "  'ModelPackageStatus': 'Completed',\n",
       "  'ModelApprovalStatus': 'PendingManualApproval'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view model package in registry\n",
    "sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList']"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
