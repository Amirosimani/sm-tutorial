{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import clarify\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Set region, boto3 and SageMaker SDK variables¶\n",
    "\n",
    "#You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "data_prefix                    -> 'sagemaker-tutorial/data'\n",
      "default_bucket                 -> 'sagemaker-us-east-1-367158743199'\n",
      "feature_group_name             -> 'FG-flow-sm-tutorial-31-16-16-17-9f41d66b'\n",
      "hyperparameters                -> {'max_depth': '3', 'eta': '0.2', 'objective': 'bin\n",
      "model_data                     -> 's3://sagemaker-us-east-1-367158743199/tf2-resnet-\n",
      "prefix                         -> 'sagemaker-tutorial'\n",
      "s3_raw_data                    -> 's3://sagemaker-us-east-1-367158743199/sagemaker-t\n"
     ]
    }
   ],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from offline feature store\n",
    "\n",
    "Feature Store provides offline storage for feature values in your S3 bucket. Your data is stored in your S3 bucket using a prefixing scheme based on event time. The offline store is an append-only store, enabling Feature Store to maintain a historical record of all feature values. Data is stored in the offline store in Parquet format for optimized storage and query access.\n",
    "\n",
    "You can query, explore, and visualize features using Data Wrangler from Amazon SageMaker Studio.  Feature Store supports combining data to produce, train, validate, and test data sets, and allows you to extract data at different points in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  THE CODE NEEDS TO CHANGE**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', \n",
    "#                                            region_name=region\n",
    "#                                           )\n",
    "\n",
    "# feature_store_session = Session(\n",
    "#     boto_session=boto_session,\n",
    "#     sagemaker_client=sagemaker_boto_client,\n",
    "#     sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    "# )\n",
    "\n",
    "# offline_feature_store_bucket = f's3://{default_bucket}/{account_id}/sagemaker/{region}/offline-store/{feature_group_name}/data/year=2021/month=03/day=31/hour=16/'\n",
    "# offline_feature_store_bucket\n",
    "\n",
    "# !aws s3 cp $offline_feature_store_bucket ../sm-tutorial/02_build_train/ --recursive\n",
    "\n",
    "# # offline_feature_store_bucket = f's3://{default_bucket}/'\n",
    "# fg_prefix = f'sagemaker/{region}/offline-store/{feature_group_name}/data/'\n",
    "# s3_client.list_objects_v2(Bucket=default_bucket,\n",
    "#                          Prefix=fg_prefix,\n",
    "#                          Delimiter='/')\n",
    "\n",
    "# def download_all_objects_in_folder():\n",
    "#     s3_resource = boto3.resource('s3')\n",
    "#     my_bucket = s3_resource.Bucket(default_bucket)\n",
    "#     objects = my_bucket.objects.filter(Prefix=offline_feature_prefix)\n",
    "#     for obj in objects:\n",
    "#         path, filename = os.path.split(obj.key)\n",
    "#         my_bucket.download_file(obj.key, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/20210331T162204Z_ATxVKv9V8rL9hJyQ.parquet to ../sm-tutorial/02_build_train/processed_data/20210331T162204Z_ATxVKv9V8rL9hJyQ.parquet\n",
      "download: s3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/20210331T162204Z_BVs0QiuqNaVyrXTY.parquet to ../sm-tutorial/02_build_train/processed_data/20210331T162204Z_BVs0QiuqNaVyrXTY.parquet\n",
      "download: s3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/20210331T162204Z_KnPgBMRO3yEo3BP3.parquet to ../sm-tutorial/02_build_train/processed_data/20210331T162204Z_KnPgBMRO3yEo3BP3.parquet\n"
     ]
    }
   ],
   "source": [
    "file_names = ['20210331T162204Z_ATxVKv9V8rL9hJyQ.parquet',\n",
    "             '20210331T162204Z_BVs0QiuqNaVyrXTY.parquet',\n",
    "             '20210331T162204Z_KnPgBMRO3yEo3BP3.parquet\t']\n",
    "\n",
    "local_processed_data = '../sm-tutorial/02_build_train/processed_data/'\n",
    "for f in file_names:\n",
    "    s3_path = f's3://sagemaker-us-east-1-367158743199/367158743199/sagemaker/us-east-1/offline-store/FG-flow-sm-tutorial-31-16-16-17-9f41d66b-1617207382/data/year=2021/month=03/day=31/hour=16/{f}'\n",
    "\n",
    "    ! aws s3 cp $s3_path $local_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "def join_parquet_files(dir_path=local_processed_data):\n",
    "    all_files = os.listdir(dir_path)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for f in all_files:\n",
    "        full_path = os.path.join(dir_path, f)\n",
    "        df_partial = pq.read_table(full_path).to_pandas()\n",
    "        df = pd.concat([df, df_partial], axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = join_parquet_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataFrame into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df_processed, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val = train_test_split(X_test, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_train.to_csv(f'{local_processed_data}/train.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_processed_data}/train.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_data_uri = response\n",
    "%store train_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'validation_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_val.to_csv(f'{local_processed_data}/validation.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_processed_data}/validation.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "validation_data_uri = response\n",
    "%store validation_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "X_test.to_csv(f'{local_processed_data}/test.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_processed_data}/test.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "test_data_uri = response\n",
    "%store test_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost details**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost hyperparameters details**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hyperparameters' (dict)\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"50\"}\n",
    "\n",
    "%store hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-tutorial'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "estimator_output_path = f's3://{default_bucket}/{prefix}/training_jobs'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", sagemaker.Session().boto_region_name, \"1.2-1\")\n",
    "\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=hyperparameters,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=estimator_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:06:03 Starting - Starting the training job...\n",
      "2021-04-01 15:06:32 Starting - Launching requested ML instancesProfilerReport-1617289563: InProgress\n",
      ".........\n",
      "2021-04-01 15:07:53 Starting - Preparing the instances for training......\n",
      "2021-04-01 15:08:58 Downloading - Downloading input data...\n",
      "2021-04-01 15:09:33 Training - Downloading the training image......\n",
      "2021-04-01 15:10:33 Uploading - Uploading generated training model\n",
      "2021-04-01 15:10:33 Completed - Training job completed\n",
      "ProfilerReport-1617289563: NoIssuesFound\n",
      "\u001b[34m[2021-04-01 15:10:15.010 ip-10-0-179-132.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 1354 rows and 28 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 339 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.16691#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.15140#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.15214#011validation-error:0.13864\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.15140#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.14993#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.15066#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.15288#011validation-error:0.15339\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.14993#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.14697#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.14623#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.14771#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.14771#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.14623#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.14402#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.14328#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.13885#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.14328#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.14180#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.14328#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.13959#011validation-error:0.14159\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.14033#011validation-error:0.14159\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.13737#011validation-error:0.14159\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.13589#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.13589#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.13368#011validation-error:0.15339\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.13294#011validation-error:0.15339\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.13294#011validation-error:0.15929\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.12998#011validation-error:0.15634\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.12998#011validation-error:0.15339\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.12703#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.12555#011validation-error:0.15339\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.12629#011validation-error:0.15634\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.12925#011validation-error:0.15634\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.12777#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.12629#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.12629#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.12703#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.11891#011validation-error:0.14159\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.11891#011validation-error:0.14159\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.12038#011validation-error:0.13569\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.11669#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.11669#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.11965#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.11965#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.11965#011validation-error:0.14454\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.12112#011validation-error:0.14159\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.11817#011validation-error:0.15044\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.11817#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.11817#011validation-error:0.14749\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.11817#011validation-error:0.15044\u001b[0m\n",
      "Training seconds: 88\n",
      "Billable seconds: 88\n"
     ]
    }
   ],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "train_input = TrainingInput(train_data_uri, content_type=content_type)\n",
    "validation_input = TrainingInput(validation_data_uri, content_type=content_type)\n",
    "\n",
    "# execute the XGBoost training job\n",
    "xgb_estimator.fit({'train': train_input, 'validation': validation_input})\n",
    "\n",
    "training_job_1_name = xgb_estimator.latest_training_job.job_name\n",
    "%store training_job_1_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-2021-04-01-15-06-03-055-model'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f'{training_job_1_name}-model'\n",
    "model = xgb_estimator.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "\n",
    "sagemaker_session.create_model(model_name,\n",
    "                     sagemaker_role,\n",
    "                     container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify\n",
    "Now that you have your model set up. Let’s say hello to SageMaker Clarify!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sagemaker_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Bias\n",
    "\n",
    "SageMaker Clarify helps you detect possible pre- and post-training biases using a variety of metrics. \n",
    "\n",
    "A `DataConfig` object communicates some basic information about data I/O to SageMaker Clarify. We specify where to find the input dataset, where to store the output, the target column (`label`), the header names, and the dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_output_path = 's3://{}/{}/clarify-bias'.format(default_bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_data_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='Target',\n",
    "                                      headers=df_processed.columns.to_list(),\n",
    "                                      dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelConfig` object communicates information about your trained model. To avoid additional traffic to your production models, SageMaker Clarify sets up and tears down a dedicated endpoint when processing. * instance_type and instance_count specify your preferred instance type and instance count used to run your model on during SageMaker Clarify’s processing. The testing dataset is small so a single standard instance is good enough to run this example. If your have a large complex dataset, you may want to use a better instance type to speed up, or add more instances to enable Spark parallelization. * accept_type denotes the endpoint response payload format, and content_type denotes the payload format of request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelPredictedLabelConfig` provides information on the format of your predictions. XGBoost model outputs probabilities of samples, so SageMaker Clarify invokes the endpoint then uses `probability_threshold` to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value 1 and below or equal as label value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing BiasConfig\n",
    "\n",
    "SageMaker Clarify also needs information on what the sensitive columns (`facets`) are, what the sensitive features (`facet_values_or_threshold`) may be, and what the desirable outcomes are (`label_values_or_threshold`). SageMaker Clarify can handle both categorical and continuous data for `facet_values_or_threshold` and for `label_values_or_threshold`. In this case we are using categorical data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>EVENT_TIME</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23659.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2293.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.617208e+09</td>\n",
       "      <td>2021-03-31 16:27:27.182000+00:00</td>\n",
       "      <td>2021-03-31 16:22:26+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20877.0</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5410.0</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>3709.0</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>5299.0</td>\n",
       "      <td>1.617208e+09</td>\n",
       "      <td>2021-03-31 16:27:27.182000+00:00</td>\n",
       "      <td>2021-03-31 16:22:26+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28236.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.617208e+09</td>\n",
       "      <td>2021-03-31 16:27:27.182000+00:00</td>\n",
       "      <td>2021-03-31 16:22:26+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23660.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5596.0</td>\n",
       "      <td>5498.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>5012.0</td>\n",
       "      <td>1.617208e+09</td>\n",
       "      <td>2021-03-31 16:27:27.182000+00:00</td>\n",
       "      <td>2021-03-31 16:22:26+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17126.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>40367.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>1.617208e+09</td>\n",
       "      <td>2021-03-31 16:27:27.182000+00:00</td>\n",
       "      <td>2021-03-31 16:22:26+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL       ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  \\\n",
       "0    0.0  23659.0   180000.0  2.0        2.0       2.0  36.0    0.0    0.0   \n",
       "1    0.0  20877.0   280000.0  1.0        1.0       1.0  38.0    1.0   -1.0   \n",
       "2    1.0  28236.0   100000.0  2.0        1.0       1.0  37.0    1.0   -2.0   \n",
       "3    0.0  23660.0   120000.0  2.0        2.0       1.0  32.0    0.0    0.0   \n",
       "4    0.0  17126.0    60000.0  2.0        2.0       2.0  26.0    1.0   -2.0   \n",
       "\n",
       "   PAY_3  ...  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0    0.0  ...    1300.0    2902.0    3047.0       0.0    2293.0    2000.0   \n",
       "1   -1.0  ...    5410.0    2380.0    3709.0    5849.0    5606.0    5299.0   \n",
       "2   -2.0  ...       0.0       0.0       0.0       0.0       0.0     150.0   \n",
       "3    0.0  ...    5596.0    5498.0    5500.0    4000.0    4300.0    5012.0   \n",
       "4   -2.0  ...       0.0       0.0    2306.0   40367.0    1416.0    1419.0   \n",
       "\n",
       "     EVENT_TIME                       write_time       api_invocation_time  \\\n",
       "0  1.617208e+09 2021-03-31 16:27:27.182000+00:00 2021-03-31 16:22:26+00:00   \n",
       "1  1.617208e+09 2021-03-31 16:27:27.182000+00:00 2021-03-31 16:22:26+00:00   \n",
       "2  1.617208e+09 2021-03-31 16:27:27.182000+00:00 2021-03-31 16:22:26+00:00   \n",
       "3  1.617208e+09 2021-03-31 16:27:27.182000+00:00 2021-03-31 16:22:26+00:00   \n",
       "4  1.617208e+09 2021-03-31 16:27:27.182000+00:00 2021-03-31 16:22:26+00:00   \n",
       "\n",
       "   is_deleted  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify this information in the BiasConfig API. Here we use `SEX` as the sensitive group.\n",
    "\n",
    "group_name is used to form subgroups for the measurement of Conditional Demographic Disparity in Labels (CDDL) and Conditional Demographic Disparity in Predicted Labels (CDDPL) with regards to Simpson’s paradox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[1],\n",
    "                                facet_name='SEX',\n",
    "                                facet_values_or_threshold=[0],\n",
    "                                group_name='AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  PRETRIANING BIAS WITH WRANGLER**</span>\n",
    "\n",
    "\n",
    "refer to smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-training Bias\n",
    "\n",
    "Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "Unbiased training data (as determined by concepts of fairness measured by bias metric) may still result in biased model predictions after training. Whether this occurs depends on several factors including hyperparameter choices.\n",
    "\n",
    "You can run these options separately with `run_pre_training_bias()` and `run_post_training_bias()` or at the same time with `run_bias()` as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  Clarify-Bias-2021-04-01-15-27-05-077\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/data/train.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/Clarify-Bias-2021-04-01-15-27-05-077/input/analysis_config/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-367158743199/sagemaker-tutorial/clarify-bias', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".............."
     ]
    }
   ],
   "source": [
    "clarify_processor.run_bias(data_config=bias_data_config,\n",
    "                           bias_config=bias_config,\n",
    "                           model_config=model_config,\n",
    "                           model_predicted_label_config=predictions_config,\n",
    "                           pre_training_methods='all',\n",
    "                           post_training_methods='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TODO:  SCREENSHOTS OF BIAS REPORT IN STUDIO**</span>\n",
    "\n",
    "https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
