{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink, FileLinks\n",
    "\n",
    "import s3fs\n",
    "import boto3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import clarify\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.debugger import Rule, rule_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region, boto3 and SageMaker SDK variablesÂ¶\n",
    "\n",
    "#You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(s3_raw_data)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the target column to the begining based on XGBoost\n",
    "cols = list(df)\n",
    "cols.insert(0, cols.pop(cols.index('default payment next month')))\n",
    "df = df.loc[:, cols]\n",
    "\n",
    "#  rename to `LABEL`\n",
    "df.rename(columns={\"default payment next month\": \"LABEL\"}, inplace=True)\n",
    "df['LABEL'] = df['LABEL'].astype('int')\n",
    "\n",
    "# drop feature store created columns\n",
    "df = df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store headers\n",
    "header = list(df.columns)\n",
    "%store header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_processed_path = f'{local_data_dir}/df_processed.csv'\n",
    "\n",
    "df.to_csv(local_processed_path, index=False)\n",
    "%store local_processed_path\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataFrame into Train, Validation & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val = train_test_split(X_test, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(f'{local_data_dir}/train.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/train.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "train_data_uri = response\n",
    "%store train_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.to_csv(f'{local_data_dir}/validation.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/validation.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "validation_data_uri = response\n",
    "%store validation_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(f'{local_data_dir}/test.csv', header=False, index=False)\n",
    "\n",
    "response = sagemaker_session.upload_data(f'{local_data_dir}/test.csv',\n",
    "                                         bucket=default_bucket, \n",
    "                                         key_prefix=data_prefix)\n",
    "test_data_uri = response\n",
    "%store test_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost details**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<span style=\"color:red\">**TODO:  XGBoost hyperparameters details**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"50\"}\n",
    "\n",
    "%store hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "estimator_output_path = f's3://{default_bucket}/{prefix}/training_jobs'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "rules=[\n",
    "    Rule.sagemaker(rule_configs.create_xgboost_report())\n",
    "]\n",
    "\n",
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=hyperparameters,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=estimator_output_path,\n",
    "                                              rules=rules\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "train_input = TrainingInput(train_data_uri, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_data_uri, content_type=\"text/csv\")\n",
    "\n",
    "# execute the XGBoost training job\n",
    "xgb_estimator.fit({'train': train_input,\n",
    "                   'validation': validation_input\n",
    "                  }\n",
    "                   )\n",
    "\n",
    "training_job_name = xgb_estimator.latest_training_job.job_name\n",
    "%store training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'{training_job_name}-model'\n",
    "model = xgb_estimator.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "\n",
    "sagemaker_session.create_model(model_name,\n",
    "                     sagemaker_role,\n",
    "                     container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugger Training Report\n",
    "\n",
    "Amazon SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning training. Amazon SageMaker Debugger helps you to monitor your training in near real time using rules and would provide you alerts, once it has detected inconsistency in training.\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**TODO:  SCREENSHOTS OF [PROFILER IN STUDIO](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-training-xgboost-report.html)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get name of profiler report\n",
    "profiler_report_name = [rule[\"RuleConfigurationName\"] \n",
    "                        for rule in xgb_estimator.latest_training_job.rule_job_summary() \n",
    "                        if \"Profiler\" in rule[\"RuleConfigurationName\"]][0]\n",
    "\n",
    "#get name of the xgboost training report\n",
    "xgb_profile_job_name = [rule[\"RuleEvaluationJobArn\"].split(\"/\")[-1] \n",
    "                        for rule in xgb_estimator.latest_training_job.rule_job_summary() \n",
    "                        if \"CreateXgboostReport\" in rule[\"RuleConfigurationName\"]][0]\n",
    "\n",
    "base_output_path = os.path.dirname(xgb_estimator.latest_job_debugger_artifacts_path())\n",
    "rule_output_path = os.path.join(base_output_path, \"rule-output/\")\n",
    "xgb_report_path = os.path.join(rule_output_path, \"CreateXgboostReport\")\n",
    "profile_report_path = os.path.join(rule_output_path, profiler_report_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_report_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    xgb_job_info = sagemaker_session.describe_processing_job(xgb_profile_job_name)\n",
    "\n",
    "    if xgb_job_info[\"ProcessingJobStatus\"] == \"Completed\":\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Job Status: {xgb_job_info['ProcessingJobStatus']}\")\n",
    "        time.sleep(30)\n",
    "\n",
    "s3.download(xgb_report_path, \"../outputs/debugger/xgb/\", recursive=True)\n",
    "s3.download(profile_report_path, \"../outputs/debugger/profiler/\", recursive=True)\n",
    "display(\"Click link below to view the profiler report whcih will help you identify hardware bottlenecks.\", FileLink(\"../outputs/debugger/profiler/profiler-output/profiler-report.html\"))\n",
    "display(\"Click link below to view the XGBoost Training reports which will help you imporve your model\", FileLink(\"../outputs/debugger/xgb/xgboost_report.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarify\n",
    "Now that you have your model set up. Letâs say hello to SageMaker Clarify!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sagemaker_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Bias\n",
    "\n",
    "SageMaker Clarify helps you detect possible pre- and post-training biases using a variety of metrics. \n",
    "\n",
    "A `DataConfig` object communicates some basic information about data I/O to SageMaker Clarify. We specify where to find the input dataset, where to store the output, the target column (`label`), the header names, and the dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_output_path = 's3://{}/{}/clarify-output/bias_1'.format(default_bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_data_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='LABEL',\n",
    "                                      headers=header,\n",
    "                                      dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelConfig` object communicates information about your trained model. To avoid additional traffic to your production models, SageMaker Clarify sets up and tears down a dedicated endpoint when processing. * instance_type and instance_count specify your preferred instance type and instance count used to run your model on during SageMaker Clarifyâs processing. The testing dataset is small so a single standard instance is good enough to run this example. If your have a large complex dataset, you may want to use a better instance type to speed up, or add more instances to enable Spark parallelization. * accept_type denotes the endpoint response payload format, and content_type denotes the payload format of request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ModelPredictedLabelConfig` provides information on the format of your predictions. XGBoost model outputs probabilities of samples, so SageMaker Clarify invokes the endpoint then uses `probability_threshold` to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value 1 and below or equal as label value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing BiasConfig\n",
    "\n",
    "SageMaker Clarify also needs information on what the sensitive columns (`facets`) are, what the sensitive features (`facet_values_or_threshold`) may be, and what the desirable outcomes are (`label_values_or_threshold`). SageMaker Clarify can handle both categorical and continuous data for `facet_values_or_threshold` and for `label_values_or_threshold`. In this case we are using categorical data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify this information in the BiasConfig API. Here we use `SEX` as the sensitive group.\n",
    "\n",
    "group_name is used to form subgroups for the measurement of Conditional Demographic Disparity in Labels (CDDL) and Conditional Demographic Disparity in Predicted Labels (CDDPL) with regards to Simpsonâs paradox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[0],\n",
    "                                facet_name='SEX',\n",
    "                                facet_values_or_threshold=[1],\n",
    "                                group_name='AGE'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-training Bias\n",
    "\n",
    "Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "Unbiased training data (as determined by concepts of fairness measured by bias metric) may still result in biased model predictions after training. Whether this occurs depends on several factors including hyperparameter choices.\n",
    "\n",
    "You can run these options separately with `run_pre_training_bias()` and `run_post_training_bias()` or at the same time with `run_bias()` as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to run clarify job\n",
    "# clarify_processor.run_bias(data_config=bias_data_config,\n",
    "#                            bias_config=bias_config,\n",
    "#                            model_config=model_config,\n",
    "#                            model_predicted_label_config=predictions_config,\n",
    "#                            pre_training_methods='all',\n",
    "#                            post_training_methods='all')\n",
    "\n",
    "# clarify_bias_job_1_name = clarify_processor.latest_job.name\n",
    "# %store clarify_bias_job_1_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: try different facets, threshold to get meaningful reports\n",
    "s3_client.download_file(Bucket=default_bucket,\n",
    "                        Key=f'{prefix}/clarify-output/bias_1/report.pdf',\n",
    "                        Filename='../outputs/clarify_output/bias_1_report.pdf')\n",
    "print(f'Downloaded clarify report from previous Clarify job: {clarify_bias_job_1_name}')\n",
    "display(\"Click link below to view the Clarify repot.\", FileLink(\"../outputs/clarify_output/bias_1_report.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**TODO:  SCREENSHOTS OF BIAS REPORT IN STUDIO**</span>\n",
    "\n",
    "https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_processing/fairness_and_explainability/fairness_and_explainability.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Lineage\n",
    "\n",
    "Amazon SageMaker ML Lineage Tracking creates and stores information about the steps of a machine learning (ML) workflow from data preparation to model deployment. With the tracking information you can reproduce the workflow steps, track model and dataset lineage, and establish model governance and audit standards. With SageMaker Lineage Tracking data scientists and model builders can do the following:\n",
    "\n",
    "* Keep a running history of model discovery experiments.\n",
    "* Establish model governance by tracking model lineage artifacts for auditing and compliance verification.\n",
    "* Clone and rerun workflows to experiment with what-if scenarios while developing models.\n",
    "* Share a workflow that colleagues can reproduce and enhance (for example, while collaborating on solving a business problem).\n",
    "* Clone and rerun workflows with additional debugging or logging routines, or new input variations for troubleshooting issues in production models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_s3_uri = training_job_info['InputDataConfig'][0]['DataSource']['S3DataSource']['S3Uri']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=training_data_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    training_data_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {training_data_artifact.artifact_arn}')\n",
    "else:\n",
    "    training_data_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainingData',\n",
    "        source_uri=training_data_s3_uri,\n",
    "        artifact_type='Dataset',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {training_data_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_s3_uri = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "matching_artifacts = list(sagemaker.lineage.artifact.Artifact.list(\n",
    "    source_uri=trained_model_s3_uri,\n",
    "    sagemaker_session=sagemaker_session))\n",
    "\n",
    "if matching_artifacts:\n",
    "    model_artifact = matching_artifacts[0]\n",
    "    print(f'Using existing artifact: {model_artifact.artifact_arn}')\n",
    "else:\n",
    "    model_artifact = sagemaker.lineage.artifact.Artifact.create(\n",
    "        artifact_name='TrainedModel',\n",
    "        source_uri=trained_model_s3_uri,\n",
    "        artifact_type='Model',\n",
    "        sagemaker_session=sagemaker_session)\n",
    "    print(f'Create artifact {model_artifact.artifact_arn}: SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set artifact associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = sagemaker_boto_client.describe_trial_component(TrialComponentName=training_job_name+'-aws-training-job')\n",
    "trial_component_arn = trial_component['TrialComponentArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input artifacts\n",
    "input_artifacts = [training_data_artifact]\n",
    "\n",
    "for a in input_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='ContributedTo',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCEESFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output artifacts\n",
    "output_artifacts = [model_artifact]\n",
    "\n",
    "for a in output_artifacts:\n",
    "    try:\n",
    "        sagemaker.lineage.association.Association.create(\n",
    "            source_arn=a.artifact_arn,\n",
    "            destination_arn=trial_component_arn,\n",
    "            association_type='Produced',\n",
    "            sagemaker_session=sagemaker_session)\n",
    "        print(f\"Association with {a.artifact_type}: SUCCESSFUL\")\n",
    "    except:\n",
    "        print(f\"Association already exists with {a.artifact_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deposit Model and Lineage in SageMaker Model Registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Package Group\n",
    "\n",
    "A Model Package Groups holds multiple versions or iterations of a model. Though it is not required to create them for every model in the registry, they help organize various models which all have the same purpose and provide autiomatic versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_name = prefix\n",
    "%store mpg_name\n",
    "print(f'Model Package Group name: {mpg_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageGroupDescription': 'Credit Defualt Prediction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_mpg = sagemaker_boto_client.list_model_package_groups(NameContains=mpg_name)['ModelPackageGroupSummaryList']\n",
    "\n",
    "if matching_mpg:\n",
    "    print(f'Using existing Model Package Group: {mpg_name}')\n",
    "else:\n",
    "    mpg_response = sagemaker_boto_client.create_model_package_group(**mpg_input_dict)\n",
    "    print(f'Create Model Package Group {mpg_name}: SUCCESSFUL')\n",
    "    %store mpg_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and upload a metrics report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_report = {'classification_metrics': {}}\n",
    "for metric in training_job_info['FinalMetricDataList']:\n",
    "    stat = {metric['MetricName']: {'value': metric['Value']}}\n",
    "    model_metrics_report['classification_metrics'].update(stat)\n",
    "    \n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics_report, f)\n",
    "    \n",
    "metrics_s3_key = f\"{prefix}/training_jobs/{training_job_info['TrainingJobName']}/training_metrics.json\"\n",
    "s3_client.upload_file(Filename='training_metrics.json', Bucket=default_bucket, Key=metrics_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'ModelQuality': {\n",
    "        'Statistics': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f's3://{default_bucket}/{prefix}/{metrics_s3_key}'\n",
    "        }\n",
    "    },\n",
    "    'Bias': {\n",
    "        'Report': {\n",
    "            'ContentType': 'application/json',\n",
    "            'S3Uri': f'{bias_report_output_path}/analysis.json'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the inference spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_spec ={    \n",
    "    \"InferenceSpecification\": {\n",
    "        \"Containers\" : [{\n",
    "            \"Image\": training_job_info['AlgorithmSpecification']['TrainingImage'],\n",
    "            \"ModelDataUrl\": training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "        }],\n",
    "        \"SupportedTransformInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\"ml.m4.xlarge\"],\n",
    "        \"SupportedContentTypes\": ['text/csv'],\n",
    "        \"SupportedResponseMIMETypes\": ['text/csv']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_input_dict = {\n",
    "    'ModelPackageGroupName': mpg_name,\n",
    "    'ModelPackageDescription': 'XGBoost classifier to detect insurance fraud.',\n",
    "    'ModelApprovalStatus': 'PendingManualApproval',\n",
    "    'ModelMetrics': model_metrics\n",
    "}\n",
    "\n",
    "mp_input_dict.update(inference_spec)\n",
    "mp1_response = sagemaker_boto_client.create_model_package(**mp_input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "mp_status = mp_info['ModelPackageStatus']\n",
    "\n",
    "while mp_status not in ['Completed', 'Failed']:\n",
    "    time.sleep(5)\n",
    "    mp_info = sagemaker_boto_client.describe_model_package(ModelPackageName=mp1_response['ModelPackageArn'])\n",
    "    mp_status = mp_info['ModelPackageStatus']\n",
    "    print(f'model package status: {mp_status}')\n",
    "print(f'model package status: {mp_status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view model package in registry\n",
    "sagemaker_boto_client.list_model_packages(ModelPackageGroupName=mpg_name)['ModelPackageSummaryList']"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
