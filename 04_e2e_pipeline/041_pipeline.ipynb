{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import boto3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, FeatureStoreOutput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AWS Region: us-east-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20210419T133759 to get Role path.\n",
      "Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "# Set region, boto3 and SageMaker SDK variablesÂ¶\n",
    "\n",
    "#You can change this to a region of your choice\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"Using AWS Region: {}\".format(region))\n",
    "\n",
    "boto3.setup_default_session(region_name=region)\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_boto_client = boto_session.client('sagemaker')\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_boto_client)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "approved_model_name                   -> 'sagemaker-tutorial-xgboost-smote'\n",
      "best_job_hp                           -> {'_tuning_objective_metric': 'validation:f1', 'alp\n",
      "clarify_bias_job_1_name               -> 'Clarify-Bias-2021-04-19-17-59-23-673'\n",
      "clarify_bias_job_2_name               -> 'Clarify-Bias-2021-04-19-18-43-09-582'\n",
      "clarify_expl_job_name                 -> 'Clarify-Explainability-2021-04-19-19-18-19-533'\n",
      "data_prefix                           -> 'sagemaker-tutorial/data'\n",
      "default_bucket                        -> 'sagemaker-us-east-1-470111782682'\n",
      "endpoint_config_name                  -> 'sagemaker-tutorial-xgboost-smote-endpoint-config'\n",
      "endpoint_name                         -> 'sagemaker-tutorial-xgboost-smote-endpoint'\n",
      "header                                -> ['LABEL', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIA\n",
      "hyperparameters                       -> {'max_depth': '5', 'eta': '0.2', 'gamma': '4', 'mi\n",
      "local_data_dir                        -> '../data'\n",
      "local_processed_path                  -> '../data/df_processed.csv'\n",
      "local_raw_path                        -> '../data/dataset.csv'\n",
      "model_2_name                          -> 'sagemaker-tutorial-xgboost-smote'\n",
      "mp2_arn                               -> 'arn:aws:sagemaker:us-east-1:470111782682:model-pa\n",
      "mpg_name                              -> 'sagemaker-tutorial'\n",
      "prefix                                -> 'sagemaker-tutorial'\n",
      "s3_raw_data                           -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "test_data_uri                         -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "test_res_data_uri                     -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "train_data_uri                        -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "train_res_data_header_uri             -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "train_res_data_uri                    -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "train_shape_data_uri                  -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "training_job_name                     -> 'sagemaker-xgboost-2021-04-19-17-47-02-323'\n",
      "training_smote_job_name               -> 'sagemaker-xgboost-210419-1832-004-272fa79f'\n",
      "validation_data_uri                   -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n",
      "validation_res_data_uri               -> 's3://sagemaker-us-east-1-470111782682/sagemaker-t\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SageMaker Pipeline to Automate All the Steps from Data Prep to Model Deployment\n",
    "Now that youve manually done each step in our machine learning workflow, you can create a pipeline which trains a new model, persists the model in SageMaker and then adds the model to the registry.\n",
    "\n",
    "### Pipeline parameters\n",
    "An important feature of SageMaker Pipelines is the ability to define the steps ahead of time, but be able to change the parameters to those steps at execution without having to re-define the pipeline. This can be achieved by using ParameterInteger, ParameterFloat or ParameterString to define a value upfront which can be modified when you call pipeline.start(parameters=parameters) later. Only certain parameters can be defined this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", 'imblearn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_param = ParameterString(\n",
    "    name=\"TrainingInstance\",\n",
    "    default_value=\"ml.m4.xlarge\"\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "deploy_model_instance_type = \"ml.m4.xlarge\"\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(Filename='./preprocessing.py', Bucket=default_bucket, Key=f'{prefix}/code/preprocessing.py')\n",
    "\n",
    "create_dataset_script_uri = f's3://{default_bucket}/{prefix}/code/preprocessing.py'\n",
    "\n",
    "\n",
    "create_dataset_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=sagemaker_role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name='credit-create-dataset',\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "create_dataset_step = ProcessingStep(\n",
    "    name='CreateDataset',\n",
    "    processor=create_dataset_processor,\n",
    "    inputs=[ProcessingInput(\n",
    "                        source=s3_raw_data,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "    outputs=[ProcessingOutput(output_name='train_data', source='/opt/ml/processing/output/train'),\n",
    "             ProcessingOutput(output_name='test_data',  source='/opt/ml/processing/output/test')],\n",
    "    job_arguments=[\"--train-test-split-ratio\", '0.8'],\n",
    "    code=create_dataset_script_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "content_type = \"text/csv\"\n",
    "job_name = f'XgboostTrain-' + strftime('%d-%H-%M-%S', gmtime())\n",
    "training_job_output_path = f's3://{default_bucket}/{prefix}/training_jobs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot training\n",
    "\n",
    "Managed Spot Training uses Amazon EC2 Spot instance to run training jobs instead of on-demand instances. You can specify which training jobs use spot instances and a stopping condition that specifies how long Amazon SageMaker waits for a job to run using Amazon EC2 Spot instances.\n",
    "\n",
    "This time in the pipeline, we will perform XGBoost training using Spot Instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: None\n"
     ]
    }
   ],
   "source": [
    "use_spot_instances = False\n",
    "max_run = 3600\n",
    "max_wait = 7200 if use_spot_instances else None\n",
    "checkpoint_s3_uri = (f's3://{default_bucket}/{prefix}/checkpoints/{job_name}' if use_spot_instances\n",
    "                      else None)\n",
    "print(\"Checkpoint path:\", checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.30)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.17.47)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.3.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.47 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.20.47)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.47->boto3>=1.16.27->sagemaker-experiments) (1.25.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.47->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.47->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20210419T133759 to get Role path.\n",
      "Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                              hyperparameters=best_job_hp,\n",
    "                                              role=sagemaker.get_execution_role(),\n",
    "                                              instance_count=train_instance_count,\n",
    "                                              instance_type=train_instance_type,\n",
    "                                              volume_size=5,  # 5 GB\n",
    "                                              output_path=training_job_output_path,\n",
    "                                              use_spot_instances=use_spot_instances,\n",
    "                                              max_run=max_run,\n",
    "                                              max_wait=max_wait,\n",
    "                                              checkpoint_s3_uri=checkpoint_s3_uri\n",
    "                                             )\n",
    "\n",
    "\n",
    "train_step = TrainingStep(\n",
    "    name=job_name,\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=create_dataset_step.properties.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri,\n",
    "        content_type=\"csv\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Pre-Deployment Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "    name='credit-default-demo-pipeline-xgboost',\n",
    "    image_uri=train_step.properties.AlgorithmSpecification.TrainingImage,\n",
    "    model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=sagemaker_role\n",
    ")\n",
    "\n",
    "inputs = sagemaker.inputs.CreateModelInput(\n",
    "    instance_type=\"ml.m4.xlarge\"\n",
    ")\n",
    "\n",
    "create_model_step = CreateModelStep(\n",
    "    name=\"ModelPreDeployment\",\n",
    "    model=model,\n",
    "    inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Bias Metrics with Clarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clarify config\n",
    "bias_report_output_path = f's3://{default_bucket}/{prefix}/clarify-output/bias'\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=create_dataset_step.properties.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri,\n",
    "    label='LABEL',\n",
    "    dataset_type='text/csv',\n",
    "    s3_output_path=bias_report_output_path)\n",
    "\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name='SEX',\n",
    "    facet_values_or_threshold=[1])\n",
    "\n",
    "analysis_config = bias_data_config.get_config()\n",
    "analysis_config.update(bias_config.get_config())\n",
    "analysis_config[\"methods\"] = {\"pre_training_bias\": {\"methods\": \"all\"}}\n",
    "\n",
    "clarify_config_dir = pathlib.Path('config')\n",
    "clarify_config_dir.mkdir(exist_ok=True)\n",
    "with open(clarify_config_dir / 'analysis_config.json', 'w') as f:\n",
    "    json.dump(analysis_config, f)\n",
    "\n",
    "s3_client.upload_file(Filename='config/analysis_config.json', Bucket=default_bucket,\n",
    "                      Key=f'{prefix}/clarify-config/analysis_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20210419T133759 to get Role path.\n",
      "Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "# clarify processing step\n",
    "clarify_processor = sagemaker.processing.Processor(\n",
    "    base_job_name='fraud-detection-demo-clarify-processor',\n",
    "    image_uri=sagemaker.clarify.image_uris.retrieve(framework='clarify', region=region),\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge')\n",
    "\n",
    "clarify_step = ProcessingStep(\n",
    "    name=\"ClarifyProcessor\",\n",
    "    processor=clarify_processor,\n",
    "    inputs=[\n",
    "        sagemaker.processing.ProcessingInput(\n",
    "            input_name=\"analysis_config\",\n",
    "            source=f's3://{default_bucket}/{prefix}/clarify-config/analysis_config.json',\n",
    "            destination=\"/opt/ml/processing/input/config\"),\n",
    "        sagemaker.processing.ProcessingInput(\n",
    "            input_name=\"dataset\",\n",
    "            source=create_dataset_step.properties.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input/data\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        sagemaker.processing.ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output/analysis.json\",\n",
    "            destination=bias_report_output_path,\n",
    "            output_name=\"analysis_result\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMetrics(object):\n",
    "    \"\"\"Accepts model metrics parameters for conversion to request dict.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_statistics=None,\n",
    "            model_constraints=None,\n",
    "            model_data_statistics=None,\n",
    "            model_data_constraints=None,\n",
    "            bias=None,\n",
    "            explainability=None,\n",
    "    ):\n",
    "        \"\"\"Initialize a ``ModelMetrics`` instance and turn parameters into dict.\n",
    "        Args:\n",
    "            model_constraints (MetricsSource):\n",
    "            model_data_constraints (MetricsSource):\n",
    "            model_data_statistics (MetricsSource):\n",
    "            bias (MetricsSource):\n",
    "            explainability (MetricsSource):\n",
    "        \"\"\"\n",
    "        self.model_statistics = model_statistics\n",
    "        self.model_constraints = model_constraints\n",
    "        self.model_data_statistics = model_data_statistics\n",
    "        self.model_data_constraints = model_data_constraints\n",
    "        self.bias = bias\n",
    "        self.explainability = explainability\n",
    "\n",
    "    def _to_request_dict(self):\n",
    "        \"\"\"Generates a request dictionary using the parameters provided to the class.\"\"\"\n",
    "        model_metrics_request = {}\n",
    "\n",
    "        model_quality = {}\n",
    "        if self.model_statistics is not None:\n",
    "            model_quality[\"Statistics\"] = self.model_statistics._to_request_dict()\n",
    "        if self.model_constraints is not None:\n",
    "            model_quality[\"Constraints\"] = self.model_constraints._to_request_dict()\n",
    "        if model_quality:\n",
    "            model_metrics_request[\"ModelQuality\"] = model_quality\n",
    "\n",
    "        model_data_quality = {}\n",
    "        if self.model_data_statistics is not None:\n",
    "            model_data_quality[\"Statistics\"] = self.model_data_statistics._to_request_dict()\n",
    "        if self.model_data_constraints is not None:\n",
    "            model_data_quality[\"Constraints\"] = self.model_data_constraints._to_request_dict()\n",
    "        if model_data_quality:\n",
    "            model_metrics_request[\"ModelDataQuality\"] = model_data_quality\n",
    "\n",
    "        if self.bias is not None:\n",
    "            model_metrics_request[\"Bias\"] = {\"Report\": self.bias._to_request_dict()}\n",
    "            # model_metrics_request[\"Bias\"] = self.bias._to_request_dict()\n",
    "        if self.explainability is not None:\n",
    "            model_metrics_request[\"Explainability\"] = self.explainability._to_request_dict()\n",
    "        return model_metrics_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    bias=sagemaker.model_metrics.MetricsSource(\n",
    "        s3_uri=clarify_step.properties.ProcessingOutputConfig.Outputs['analysis_result'].S3Output.S3Uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if 'mpg_name' not in locals():\n",
    "    mpg_name = prefix\n",
    "    print(f'Model Package Group name: {mpg_name}')\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"XgboostRegisterModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=mpg_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"xgboost-model-pipeline-\" + strftime('%d-%H-%M-%S', gmtime())\n",
    "deploy_model_script_uri = f's3://{default_bucket}/{prefix}/code/deploy_model.py'\n",
    "\n",
    "\n",
    "s3_client.upload_file(Filename='deploy_model.py', Bucket=default_bucket, Key=f'{prefix}/code/deploy_model.py')\n",
    "\n",
    "deploy_model_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=sagemaker_role,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    base_job_name='fraud-detection-demo-deploy-model',\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "deploy_step = ProcessingStep(\n",
    "    name='DeployModel',\n",
    "    processor=deploy_model_processor,\n",
    "    job_arguments=[\n",
    "        \"--model-name\", create_model_step.properties.ModelName,\n",
    "        \"--region\", region,\n",
    "        \"--endpoint-instance-type\", deploy_model_instance_type,\n",
    "        \"--endpoint-name\", endpoint_name],\n",
    "    code=deploy_model_script_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the Pipeline Steps and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = f'credit-default'\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        train_instance_param,\n",
    "        model_approval_status],\n",
    "    steps=[\n",
    "        create_dataset_step,\n",
    "        train_step,\n",
    "        create_model_step,\n",
    "        clarify_step,\n",
    "        register_step,\n",
    "        deploy_step\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline definition to the SageMaker Pipeline service\n",
    "\n",
    "Note: If an existing pipeline has the same name it will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:470111782682:pipeline/credit-default',\n",
       " 'ResponseMetadata': {'RequestId': 'b274552a-cfa1-4cf1-9a43-0165851373f1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b274552a-cfa1-4cf1-9a43-0165851373f1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Mon, 19 Apr 2021 21:29:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=sagemaker_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full pipeline will take up to 30 min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_response = pipeline.start()\n",
    "\n",
    "start_response.wait()\n",
    "start_response.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "After running the demo, you should remove the resources which were created. You can also delete all the objects in the project's S3 directory by passing the keyword argument delete_s3_objects=True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import delete_project_resources\n",
    "\n",
    "delete_project_resources(\n",
    "    sagemaker_boto_client=sagemaker_boto_client,\n",
    "    endpoint_name=endpoint_name, \n",
    "    pipeline_name=pipeline_name, \n",
    "    mpg_name=mpg_name, \n",
    "    prefix=prefix,\n",
    "    delete_s3_objects=False,\n",
    "    bucket_name=default_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
